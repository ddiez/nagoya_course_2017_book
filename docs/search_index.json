[
["index.html", "Introduction to Bioinformatics About", " Introduction to Bioinformatics Diego Diez 2017-12-11 About This book includes some of the topics covered during the intensive course Introduction to Bioinformatics held in at Nagoya University in Dec 13-14, 2017. It does not try to be particularly comprehensive but serve as a small guide for the students. Some parts of these book are inspired by my edX lectures Introduction to Systems Immunology. "],
["prerequisites.html", "Prerequisites", " Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need to install XeLaTeX. "],
["intro.html", "Chapter 1 Introduction 1.1 Sequence analysis 1.2 Omics analysis 1.3 Structural analysis 1.4 Phylogenetic analysis", " Chapter 1 Introduction Bioinformatics can be defined as the use of computational methods to answer questions in Biology. Another way to define it is as the field concerned with the development of such tools. Another related name is Computational Biologist, which refers to a Biologist that use mainly Bioinformatics tools to tackle questions in Biology. All these terms can be confusing but here we will put our focus on the Biologist point of view. From that perspective Bioinformatics is just a tool, in the same way as Molecular Biology is, that can help us to get insight into Biology. Another confusion comes from the overlap with other fields like Statistics and Computer Science. This is because researchers that use Bioinformatics tools may inevitably end up using also methods and tools from Statistics, Computer Science, Machine learning, etc. Here we will concentrate on the description of mainly purely Bioinformatics tools. However, it is unavoidable that reference and/or knowledge of these other fields will be required to have some understanding of how Bioinformatics tools work, and also to be able to interpret the results from Bioinformatics tools. Bioinformatics is a very broad terms covering and overlapping with other previously existing fields. Some of the topics touched by Bioinformatics include: Sequence analysis Phylogenetic analysis Omics analysis Structural analysis Below we will briefly describe each of these topics. In this introductory course, however, we will focus on two topics, sequence analysis and omics analysis. 1.1 Sequence analysis The main goal of sequence analysis is two answer questions regarding DNA, RNA and/or protein sequences. For example, we could be presented with an unknown sequence, like the one shown here: MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAG QEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHHYREQIKRVKDSEDVPMVLVGNKCDL PSRTVDTKQAQDLARSYGIPFIETSAKTRQRVEDAFYTLVREIRQYRLKKISKEEKTPGC VKIKKCIIM The question is what can we learn about this unknown sequence identity from the sequence information alone. In particular, we can ask: Are there any other similar sequences? What parts of the sequences are similar and which one are not? Can we see a conservation pattern among a set of sequences? What is its function? Sequence analysis deals with the methods used to answer some of these questions. 1.2 Omics analysis In omics analysis we are concerned with the manipulation, processing and analysis of high-throughtput data from omics technologies, including microarrays, next generation sequencing (NGS) and mass-spectromemtry (MS). High-throughput here means that we are concerned with measuring the expression of, for example, all the transcripts in the cell, not just a small number of them. We may also be interested on the information about all the proteins, or all the metabolites, etc. Omics technologies enables this to be done, and generate large datasets with information about all the molecular components of the cell. For example, we can consider an study in which the effect of some drug on the expression profile of some cells will be evaluated. Mice are treated with either the drug or some placebo. Cells are isolated from the tissue and RNA is extracted. After amplification and convertion into cDNA we hybridize the samples to microarrays containing probes for &gt;55 thousand transcripts. This will give us an estimate of the expression profile for 55 thousand transcripts. If we have initially 3 samples per group, we will obtain a 55,000 x 6 matrix of expression values. Omics analysis deals with problems associated with the manipulation, processing and analysis of omics datasets. How can we process and analyze this data in a way that avoids biases and gives us some information about the biological question of interest? 1.3 Structural analysis Structural bioinformatics deals with methods predicting the structure of biopolymers and their interactions with one another as well as with small molecules. It can be very important in order to decipher the mechanism of action of some drugs. 1.4 Phylogenetic analysis Phylogenetic analysis is concerned with the evolutionary relationships between biological sequences and what can that tell us about the evolution of species. It uses information directly related with the sequence analysis methods described above, and includes additional methods to talckle specific questions in the field. "],
["sequence-analysis.html", "Chapter 2 Sequence analysis 2.1 Pairwise alignment 2.2 Scoring matrices 2.3 Blast 2.4 Multiple sequence alignment 2.5 Tree methods 2.6 Domains and motifs 2.7 Phylogenetics", " Chapter 2 Sequence analysis This chapter introduces the basics of sequence analysis methods. As mentioned in Section 1.1 (Sequence analysis), the main goal of sequence analysis is two answer questions regarding DNA, RNA and/or protein sequences. For example, we could be presented with an unknown sequence, like the one shown here: MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAG QEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHHYREQIKRVKDSEDVPMVLVGNKCDL PSRTVDTKQAQDLARSYGIPFIETSAKTRQRVEDAFYTLVREIRQYRLKKISKEEKTPGC VKIKKCIIM Since we only have the amino acid sequence, the first thing we may want to do is to compare these sequence with the sequence of other proteins in order to see whether we find other proteins that look similar. The process of comparing two sequences to figure out their similarity is called sequence alignment. 2.1 Pairwise alignment Imagine we could find a known protein for which 100% of its amino acid sequence is identical with our unknown sequence. Then we could say we have identified our protein! Imagine however that not all the amino acids are exactly identical. At some positions we may have some changes. The more changes we have, the more disimilar the two sequences will be. We want a way to quantitatively measure how much different (or similar) two sequences are. This is represented below by the two DNA sequences (seq1 and seq2) which are put together. The sequence of dots and asteriks below indicates whether the two aminoacids aligned are identical (and then is a .) or different (and then is a *). seq1 A A G G A T G A seq2 A A C G A T A A . . * . . . * . It is possible for the sequences to not be the same lengths. In that situation the residue positions not matching to any other residue in the other sequence are indicated with the gap symbol -. Gaps, however, may appear also when comparing sequences of the same length. seq3 A A G G A T G G A seq2 A A C G A T A - A . . * . . . * * . When aligning two sequences we need to specify a scoring system. This is a matrix with a score proportional to the probability of the change in residue happening. A simple scoring system could be the following: +1 when the two residues are the same, -1 otherwise: A G T C A 1 -1 -1 -1 G -1 1 -1 -1 T -1 -1 1 -1 C -1 -1 -1 1 If we consider this scoring system, the score of the following alignment can be calculated using the information in the scoring matrix. In the following example + indicates the +1 score and - the -1 score. seq1 A A G G A T G A seq2 A A C G A T A A + + - + + + - + score: 6 * (+1) + 2 * (-1) = +4 When there are gaps, a score for the gap needs to be specified. For example, we could use a score of -1 and the score of the gapped alignment above can be computed accordingly. seq3 A A G G A T G G A seq2 A A C G A T A - A + + - + + + - - + score: 6 * (+1) + 3 * (-1) = +3 Different alignments will produce different scores. For example, we could have aligned the seq3 and seq2 in a different way. seq3 A A G G A T G G A seq2 A A C G A T A A - + + - + + + - - - score: 5 * (+1) + 4 * (-1) = +1 This alignment produces a smaller score and therefore is not as optimal as the original one. The goal of sequence alignment algorithms is to find the optimal alignment, that is, the aligment that maximizes the score. It is important to notice that sometimes there is best alignment. For example, consider this alternative alignment. seq3 A A G G A T G G A seq2 A A C G A T - A A + + - + + + - - + score: 6 * (+1) + 3 * (-1) = +3 There is a slight difference in where the second-to-last A in seq2 is located. Both alternatives produce the same score, so there is no way to know which one is the best. There are two main methods to perform sequence alignment: global and local. In global alignment the two sequences are aligned along their entire lengths, and the best alignment is returned. This means every residue of a sequence is aligned to a residue of the other sequence or to a gap. In local alignment the best subsequence alignment is found. Global alignment is used to compare two sequences end-to-end, whereas local alignment is used to identify the parts of the sequences that are most similar. For example, using the scoring system above, we can compute the result from global and local aligment for seq2 and seq3 using the Biostrings package in Bioconductor: Global PairwiseAlignmentsSingleSubject (1 of 1) pattern: [1] AAGGATGGA subject: [1] AACGATA-A score: 3 Local PairwiseAlignmentsSingleSubject (1 of 1) pattern: [1] AAGGAT subject: [1] AACGAT score: 4 Global aligment is alse called Needleman-Wunsch whereas local aligment is called Smith-Waterman. You can see more details regarding how these two algorithms work in their wikipedia pages, or in the excellent O’Reilly book BLAST: An essential guide to the Basic Local Alignment Search Tool. A more advanced book on the topic of sequence aligment is Biological sequence analysis: Probabilistic models of proteins and nucleic acids. 2.2 Scoring matrices In reality we do not use a scoring matrix like the one above. We want to use scoring matrices that reflect how residues (whether amino acid or nucleotide) change in nature. For protein sequences there are two main types of matrices used in sequence aligments: BLOSUM and PAM. I will briefly describe BLOSUM matrices here. BLOSUM stands for BLOcks SUbstitution Matrix. BLOSUM matrices are empirical, derived from local aligment of protein sequenes found in databases (originally in the BLOCKS database). The matrix number indicates the selection process for including sequences into the computatiom. For example, the BLOSUM62 matrix includes aligments of sequences with less than 62% similarity. Here you can see a fragment of the BLOSUM62 matrix. A R N D C Q E G H I A 4 -1 -2 -2 0 -1 -1 0 -2 -1 R -1 5 0 -2 -3 1 0 -2 0 -3 N -2 0 6 1 -3 0 0 0 1 -3 D -2 -2 1 6 -3 0 2 -1 -1 -3 C 0 -3 -3 -3 9 -3 -4 -3 -3 -1 Q -1 1 0 0 -3 5 2 -2 0 -3 E -1 0 0 2 -4 2 5 -2 0 -3 G 0 -2 0 -1 -3 -2 -2 6 -2 -4 H -2 0 1 -1 -3 0 0 -2 8 -3 I -1 -3 -3 -3 -1 -3 -3 -4 -3 4 As you can see the diagonal contains positive scores (e.g. A-&gt;A score 4), indicating that identity is highly favored. Not all scores in the diagonal are equal. This reflects that some identities are more strongly enforced that others. For example, the score for D-&gt;D is 6, indicating that this identity happens more frequently than A-&gt;A. This probably reflect the fact that an A can be replaced by more amino acids without causing a big disruption in the structure than if the change involves a D. Some of the positions are 0, and some others are negative, indicating non-favorable substitutions. For example, the change E-&gt;C has a score of -4 indicating that it doesn’t happen often, probably because is not favored. 2.3 Blast Searching for similar sequences in a large sequence database can be computationally expensive because the SW algorithm is relativelly slow. Therefore, some alternatives using heuristics have been developed over the years. One such alternative is Blast. Blast stands for Basic Local Alignment Tool. Blast uses some heuristics to improve the speed of the local alignment and therefore can be used to search for large sequence databases. Often the quality of the alignment is as good as the one we could obtain with SW, however, it is possible to loose some accuracy. The NCBI Blast web server can be used to search for sequence similarity against a wide range of sequence databases hosted at NCBI. Blast searches are also available at many other sequence database resources like EnsEMBL and Uniprot. For example, we can use the NCBI Blast service to identify our unknown sequence at the begining of this chapter. Go there and click on Protein BLAST. A web form will show. Copy/paste our unknown sequence on the textbox saying Enter accession number(s), gi(s), or FASTA sequence(s). Click the blue rounded button saying BLAST. Wait a few seconds (or minutes depending on the network load) for the result page to show. Figure 2.1: Standard Protein Blast submit form. The result page will look something like this. Figure 2.2: Standard Protein Blast result page (top). Figure 2.3: Standard Protein Blast result page (hit list). We can see from this list that the first hit is the human GTPase KRas. This is reassuring since that is indeed the sequence I downloaded (from Uniprot) and included at the beginning of this chapter. 2.4 Multiple sequence alignment When we want to align 3 o more sequences together we have a multiple sequence alignment (MSA). In a MSA there is more ambiguity about what determines a correct alignment. Also, finding the best aligment in terms of scoring scheme is more computationally expensive. Therefore, MSA software uses heuristics to find good but often sub-optimal solutions. Here you can see a MSA of four sequences, members of the Ras family. Three of them correspond to human sequences, the last one to mouse RASH. Figure 2.4: Multiple sequence aligment of RAS protein family members. Software for MSA: MAFFT Clustal (Classic) MUSCLE 2.5 Tree methods Sequence aligment methods give us information about the similarity between different sequences. Some sequences are more similar to one another than to other sequences. Although this information is somwhat visible in the MSA, it is difficult to visualize complex similarity relationships when many sequences are considered. To help with this problem tree visualization methods can be useful. Tree methods use a distance matrix, e.g. derived from pairwise sequence aligment of a set of sequences, and constructs a binary tree in which proteins closer in the tree are more similar. For example, take a look at the tree shown in Figure 2.5 for the 4 RAS proteins. Figure 2.5: Phylogenetic tree of 4 RAS proteins. 2.6 Domains and motifs Biological sequences contain regions of high similarity to other similar regions in other proteins. Sometimes this regios are small, accounting for a few aminoacids, and they are typically named motifs. In other cases the conserved regions are larger, and then are called domains. Domains are sometimes associated with some structurally motivated definition of domain. Sometimes however, the distinction between these two types of conserved regions is ambigous. Motifs and domains can be identified as those conserved regions in a MSA. This information then can be encoded into a Position Specific Scoring Matrix (PSSM), also called Position Weight Matrix (PWM). PSSMs contain information about how likely a particular residue is to be found at a particular position. Therefore, unlike substitution matrices, PSSMs are typically not square or symmetric. Here is the PSSM of the binding motif for the mouse Stat3 transcription factor, obtained from the Jaspar database. &gt;MA0144.1 Stat3 20 13 38 6 321 8 6 585 606 191 19 10 552 541 21 0 2 21 1 15 25 129 9 1 148 605 592 7 5 393 549 461 14 65 123 0 13 0 1 14 This matrix represents a motif 10 residues length. It is a DNA motif so the number of rows is four, representing respectivelly A, C, G and T. Each column sums up to 613. This means that we started with a 10 residues length MSA containing 613 sequences. At each position we count the number of times a particular letter appears. For example in the first position T happens 549 times. This form of the motif is also called Position Count Matrix or PCM, because it shows the actual counts. We can transform into frequencies by dividing each column by the total number of counts (613 in this case). We obtain then a Position Frequency Matrix or PFM. [,1] [,2] [,3] [,4] [,5] [,6] [1,] 0.03262643 0.02120718 0.06199021 0.009787928 0.52365416 0.01305057 [2,] 0.03099511 0.01631321 0.90048940 0.882544861 0.03425775 0.00000000 [3,] 0.04078303 0.21044046 0.01468189 0.001631321 0.24143556 0.98694943 [4,] 0.89559543 0.75203915 0.02283850 0.106035889 0.20065253 0.00000000 [,7] [,8] [,9] [,10] [1,] 0.009787928 0.95432300 0.988580750 0.31158238 [2,] 0.003262643 0.03425775 0.001631321 0.02446982 [3,] 0.965742251 0.01141925 0.008156607 0.64110930 [4,] 0.021207178 0.00000000 0.001631321 0.02283850 This information can also be represented using Sequence Logos. In this approach we plot at each position all the letters, with each letter height proportional to the probability (In reality it is proportional not to the probability directly but to the information content or bits). For example here is the sequence logo for Stat3. You can see that the letters at position 5 are all small. This is because the probabilities are more uniform. There is no clear residue dominating the binding at that position. So we have less information about what residue should be in that position. PSSM are commonly used to encode the binding motifs of transcription factors, and this information is collected in databases like Jaspar. Then tools like MEME can be used to identify the binding sites of transcription factors in the genome. PSSMs are also used in a variant of Blast called PSI-BLAST. Basically PSI-BLAST performs a round of Blast, then construct at PSSM from a MSA of the best hits, then use this PSSM to iterativelly search the same database, refining the PSSM each cycle with the best hits. This approach results in improved sensitivity. A similar approach is followed in the Pfam database. In Pfam MSAs containing the domain of interest are manually curated (also known as seed alignments). These alignments are used to train a Hidden Markov Model (HMM) that learns how to recognize the same domain in other sequences. With this HMM, we can identify all sequences in a database containing that particular domain. HMM models are learned using the software HMMER. 2.7 Phylogenetics Biological sequences with a commoen evolutionary origin are called homologs. Homolog sequences found in different species are called orthologs. Homologs within the same species (i.e. originated by e.g. a gene duplication event) are called paralogs. Because of the shared ancestry homologs share similarity at the sequence level. The closer homologs, i.e. the less time has passed since the two sequences diverged, the more similar the two sequences will be. Therefore, sequence similarity is often used as evidence for homology, i.e. common ancestry. Here we do not get into the problem of phylogenies but a good starting point is the classic Molecular evolution and phylogenetics by M. Nei, creator of the popular Neighbor-Joining method for tree reconstruction. "],
["omics-analysis-1.html", "Chapter 3 Omics analysis 3.1 Introduction 3.2 Microarrays 3.3 Next-generation sequencing 3.4 Mass spectromics methods 3.5 Single cell omics", " Chapter 3 Omics analysis This chapter introduces the basics of the most commonly used omics technologies. 3.1 Introduction What is omics? In the last 20 years there has been an explosion of words ending in ~ome and ~omics in the scientific literature. All these words probably derive from the word genome and genomics. The definition for genome in a classic textbook in Biology says: “Genome is the complete set of genes of an organism”. Genomics, would be the science that studies the genome. In a similar way, all the RNA molecules expressed in a cell at a particular time is called the transcriptome. For all the proteins expressed in a cell we use proteome. For all the metabolites we use metabolome, and so on. The ome word ending is also used to describe the complete set of other things, not necessarily molecules but some kind of property, feature or virtually almost anything. For example, interactome may refer to the complete set of protein-protein, protein-DNA and protein-RNA interactions. Extensions of this terminology have resulted in the appearance of terms like phenome, diseasome, and so on. The technologies used to study omes are called omics. For example, transcriptomics is the field that studies the transcriptome. Proteomics is the study of the proteome, etc. This leads to a whole world of omics technologies. Figure 3.1: A world of OMICS technologies. Let’s look into the basic idea behind one of these technologies and what kind of information they allow us to obtain. For example, in Figure 3.2 we can see one cell (the two black circles) before and after exposure to some stimulus. Transcripts are represented by the ribbons, each color being a different transcript. Imagine we are interested on the effect of some chemical on our cells. We hypothesize that the expression level of some genes may be altered by the effect of the stimulus, but we do not know whether this is true or what genes may be altered. We decide to do transcriptomics, or gene expression profiling, to identify which genes are affected. Here we can see the result from such experiment. In this hypothetical scenario gene 1 has two transcripts, but only the first one is downregulated, i.e. its expression is reduced after exposure to the stimulus. Gene 4 has one transcript that is upregulated, i.e. its expression is increased by the stimulus. Other transcripts appear unchanged. The expression level for all transcripts at a given condition is called the expression profile. By comparing expression profiles we can reveal which genes are altered between the different conditions. These are called differentially expressed genes (DEGs). One of the goals of transcriptomics is to identify DEGs between different experimental conditions (for example, between control and treatment, patient and disease, etc.). Figure 3.2: Rationale behind OMICS technologies. Existing omics technologies can be roughly divided into three categories: microarray based, next generation sequencing approaches (or NGS) and mass-spectrometry methods (or MS). We will briefly describe some of these techniques in the following sections. Figure 3.3: Classification of OMICS technologies. 3.2 Microarrays Microarrays were arguably the first of the “omics” technologies, starting a new generation of high-throughput analyses. This type of exploratory analysis enables the generation of new hypotheses that can be further tested, becoming one important source of knowledge discovery. Microarrays were the first technology to allow this and currently there is a wealth of experimental data available in public databases. There are over 50,000 samples for expression microarrays deposited in the NCBI gene expression omnibus (Figure 3.4). Figure 3.4: Number of total submissions for the top 4 technologies. Microarrays are basically made of a solid surface with short oligonucleotides attached to it (see Figure 3.5). Each oligonucleotide has a specific sequence, complementary to a particular gene transcript. This makes the oligonucleotide a probe for the expression level of the target transcript. The solid surface is divided into regions forming an array. Each region has attached the same oligonucleotide and therefore can detect the same transcript. Figure 3.5: Microarrays are made of oligonucleotide probes attached to a solid surface. Microarrays were initially develop to perform transcriptomics, i.e. study transcription profiles. It was later adapated to study other interesting aspects of Biology, like the binding of transcription factors to the DNA (using ChIP-on-chip) or patterns of human variation (using SNP arrays). Here we will focus on expression microarrays. In Figure 3.6 we can see a typical microarray experiment protocol in more detail. The RNA extracted from the target cells is converted into cDNA using nucleotides with a fluorescence molecule attached. A hybridization reaction is performed to allow the labelled cDNA to bind to its complementary probes in the microarray. The location of the hybridized probes is revealed by exciting the array with a laser (scanning). Only those regions with cDNA bound will emit fluorescence upon stimulation with the laser. Because the location and sequence of the oligonucleotides in the microarray are known, the location of the fluorescence will tell us which transcript has been detected. Image analysis is performed to quantify the signal associated with each probe, obtaining an estimate of the transcript’s expression level. Analysis of the raw data involves preprocessing of the intensities (usually background correction and normalization) and statistical analysis. Variants of this basic protocol exist that use different labeling approaches, detection methods, amplification of original RNA, etc. Figure 3.6: Summary of typical microarray workflow. 3.3 Next-generation sequencing An important limitation of microarrays is that they are based on oligonucleotide probes for detecting expression. This means microarrays can only detect molecules for which a probe exists in the array. The probes in a microarray are based on our knowledge of the genome’s sequence at the time of microarray design. Because our knowledge is not perfect, microarrays often contain probes measuring things different to what were originally intended. This may lead to incorrect conclusions if the information about the most likely target sequence is not up to date. Instead of using a probe to quantify the presence of a DNA or RNA molecule, why not just sequence the molecule? The problem was that existing sequencing technology was slow and expensive. This motivated the development of so called Next Generation Sequencing technologies, or NGS. Let’s look into the fundamental concept behind all NGS technologies from the perspective of transcriptomics (Figure 3.7). Imagine this gene containing one intron and both 5’ and 3’ UTRs. The gene is transcribed into a messenger RNA (mRNA). The mRNA is extracted from the cell and converted into cDNA. This cDNA is used in microarray technology for the hybridization reaction. In NGS however, the cDNA is ligated to sequencing primers, and sequencing produces a set of short reads. Then, these reads are mapped back to the genome using sequence alignment. The location and number of reads will reveal, after correcting from biases like sequencing depth and transcript length, which genes are being expressed and their abundance levels. There are many applications of NGS technologies. Next we will review two of the most popular. Figure 3.7: Summary of rationale behind NGS technologies. 3.3.1 RNA-seq The most popular application of NGS technologies is RNA-seq, a technology to measure the transcriptome (Figure 3.8). This slide shows a summary of the typical RNA-seq protocol. Isolate and fragment the RNA. A sequencing library is generated by converting the fragmented molecules into double stranded cDNA and ligating sequencing primers to the ends. The cDNA library is sequenced, resulting in a lot of oligonucleotide sequences called “reads”. The reads are aligned to a reference genome. The coverage at each genome location is defined as the number of overlapping reads. This density is proportional to the original molecule’s concentration. Therefore, molecules found at higher concentrations will show larger “peaks”. Computational methods are used to quantify the peaks overlapping gene sequences. Statistical methods are used to identify genes with differences in expression level. Because we are not limited to pre-specified sequence probes we can use the NGS data to detect the expression of alternative splice variants, non-coding RNAs, genetic variants (or SNPs) and even the expression of uncharacterized transcripts. Also, if the reference genome information is updated, the original data can be realigned, never becoming obsolete and possibly revealing additional information. This versatility increases dramatically the amount of information that can be obtained from a single experiment, making RNA-seq one of the most widely used omics technologies. Figure 3.8: Summary of typical RNA-seq workflow. Example: Stat3 expression in macrophages exposed to IL10 In the following example we will look into an RNA-seq experiment in more detail. Figure 3.9 shows the mouse Stat3 locus including the exon/intron structure of the different transcripts as yellow boxes and lines. You can see also other genes nearby, like Stat5a. The expression level in resting and IL10 stimulated macrophages is shown as the peaks overlapping with the exons. Figure 3.9: Expression of Stat3 in macrophages exposed to IL10. Those peaks represent the density of reads mapping to the genome (Figure 3.10). The expression level can be computed from the area of the peaks. Here we see that the expression level of Stat3 is increased in IL10 treated macrophages. From this picture we can also see some of the difficulties found when interpreting this type of data. For example, which of all the Stat3 transcripts are expressed and which are regulated? Answering this question requires more sophisticated analysis and possibly additional experiments designed specifically to gather supporting evidence. Figure 3.10: Expression of Stat3 in macrophages exposed to IL10. In Figure 3.11 we can see more details for one of the samples, with the coverage and the aligned reads below. These dense grey boxes are the actual sequenced reads. Figure 3.11: Expression of Stat3 in macrophages exposed to IL10. Let’s take a closer look to this region near the first exon (Figure 3.12). You can see here this boxes indicating the length of the reads and the arrowed end the strand to which they align. If we take an even closer look we can see now the reads in more detail. From this picture you can verify that the coverage is the number of reads overlapping at each genomic location. Here the grey boxes indicate that the read sequence matches that of the reference genome to which they have been aligned. Some of these reads locations, however, show mismatches. These are probably sequencing errors, but if a location shows a mismatch consistently found in all reads it will suggest a SNP in the assayed specimen compared to the reference genome. Figure 3.12: Expression of Stat3 in macrophages exposed to IL10. 3.3.2 ChIP-seq Another popular NGS technology is ChIP-seq, which stands for chromatin immunoprecipitation followed by NGS sequencing. In ChIP-seq we aim to identify protein-DNA interactions. That is, we want to know the sequence of the DNA to which a DNA-binding protein binds. This information is critical to understand gene regulatory programs. For example, gene transcription is regulated by transcription factors that bind to specific regions in the genome, including gene promoters and enhancers. Also, histones represent another type of DNA binding proteins with important roles in the regulation of gene expression. Posttranscriptional histone modifications, like acetylation, methylation, and others, are associated with regulatory outcomes, like expression activation and repression. ChIP-seq enables to study many of these patterns at genome wide scale. The basic ChIP-seq protocol is shown in Figure 3.13. First, proteins are fixed to the DNA with, e.g. formaldehyde. Then, the chromatin is fragmented, leading to many small fragments free of proteins and some with proteins bound. Among the later ones, some will be bound to the target protein, that can be a transcription factor or a histone with some particular modification like H3K9me3 (tri-methylation of lysine in position 9 of the histone H3). Next, we use an antibody against the target protein for an immunoprecipitation, which allows us to obtain the proteins and the DNA sequences they are bound to. Then we remove the fixation and isolate the DNA. The rest of the protocol, cDNA library construction and sequencing are performed similarly to RNA-seq. Sequencing will produce sequence reads that can be aligned to the reference genome. The read peaks accumulating in DNA loci will reveal where the target protein was bound. Computational methods are used to identify and quantify the peaks. Statistical analysis will help us determine if there is differential binding between experimental conditions. Figure 3.13: ChIP-seq workflow. Example: Stat3 binding in macrophages exposed to IL10 In the following example we can see an application of ChIP-seq to identify the binding locations of the transcription factor Stat3 in macrophages after exposure to Il10. As before, the Stat3 locus in the mouse genome is shown, together with the coverage for the Stat3 ChIP-seq experiment. We can see that Stat3 binds to its own promoter upon Il10 treatment, suggesting that it regulates its own expression. Figure 3.14: Stat3 binding profile around the Stat3 locus An important limitation of ChIP-seq is that it can only identify binding sites for a single TF or histone modification at a time. Another problem is that in eukaryotes, enhancers can be located far away from the genes they regulate, hampering the assignment of TF binding to target genes. Finally, the observation of protein binding to DNA does not demonstrate its functional relevance, which requires additional functional experiments. 3.3.3 Other NGS technologies Other NGS technologies are becoming popular in recent years. For example, TSS-seq and CAGE-seq are technologies that identify the 5’ cap structure of the processed mRNA, revealing the location of active promoters. Other technologies are able to reveal information about the chromatin. Chromatin accessibility can be assayed by means of either DNaseI digestion or by transposase reaction. In both cases the enzymes have a preference to react with open chromatin regions, with regions of close chromatin or protected by the binding of proteins being more resilient. This enables to map open chromatin and even the location of nucleosomes and binding of TFs if enough sequencing depth is performed. Nucleosome location can be more directly assayed by using the Mnase-seq protocol. Finally, the methylation of the DNA can be assayed by bisulfite sequencing. 3.4 Mass spectromics methods Studying transcriptional regulation is one important part for understanding the cell’s phenotype. But some of the transcribed genes will produce proteins that engage in diverse functions in the cell, including signaling pathways that regulate the cell’s behavior and enzymes that regulate metabolic pathways. Therefore, the other important part to understand the cell’s phenotype are the proteome and metabolome. For studying the proteome mass-spectrometry (or MS) approaches have been fundamental. Here we will focus on the use of MS approaches for proteomics. MS uses the mass-to-charge ratio to identify and quantify chemical molecules. MS is used not only to quantify protein expression, but also post-translational modifications like phosphorylation or ubiquitination, and protein-protein interactions. 3.4.1 MS The general proteomics protocol requires digesting the proteins into fragments (peptides). These will be initially separated by liquid chromatography (LC) coupled to MS. This will lead to peptide separation but identification requires another round of fragmentation followed by MS. Each peptide produces a distinct spectrum, which is compared against a database linking spectra to peptide sequences. The identified peptides are then mapped to a protein database to identify the proteins they came from. The number of mapping peptides will be proportional to the original abundance of the proteins, enabling their quantification. Figure 3.15: Workflow for MS proteomics. 3.4.2 AP-MS Protein interactions are fundamental in regulating cellular pathways, and they play as well important roles in immunology. To obtain protein-protein interaction information we can use a modified MS protocol called AP-MS (affinity purification followed by MS). Similar to ChIP-seq, the first step is to crosslink interacting proteins together with formaldehyde. Next, we isolate the complexes with an antibody against the target protein, also call the bait. Then, crosslinking is reversed, the proteins are digested and LC-MS/MS performed in the usual way. Mapping the peptides to the proteome will identify which other proteins where interacting with our target protein. AP-MS can only assay the interactome around the target protein. Also, it does not identify direct interactions, but proteins that are part of the same protein complex. Figure 3.16: Workflow for AP-MS proteomics for identifying protein-protein interactions. 3.5 Single cell omics So far we have assumed that in each omic experiment we obtain a tissue sample, or perhaps isolate the cell type of interest with FACS and then perform the analysis on the bulk of cells. An experiment performed in this way reveals information about (in the case of transcriptomics) the average expression level of all cells in the bulk. In general, this approach is valid if we believe that most of the cells in the population are similarly and that they behavior is homogeneous. However, recent evidence shows that even in seemingly homogenous populations, there is substantial heterogeneity in the expression levels of genes and proteins. This is even more dramatic in populations where a few cells are regulated distinctly and initiate changes that will drive future responses. For example, in the lymph node there are many naive T cells but only the ones in contact with their specific antigen will be activated and mature into effector cells. Because the associated changes occur in a very limited number of cells, that information may be lost in the averaging resulting from analyzing bulks of cells. This is the motivation behind the field of single cells omics. The foundation of single cell omics is almost identical to what we have seen so far. The main difference is that these omics technologies are applied to each cell individually, requiring of methods to manipulate and extract the target material from single cells in parallel and efficiently. Another challenge is the analysis of this type of data. The data resulting from single cell omics is multivariate in nature and specialized methods are required for their interpretation. Figure 3.17: Single cell omics captures the stochastic nature of biological processes The field of single cell omics is in constant development and new or improved methodologies appear increasingly. For transcriptomics the use of microfluidic reaction chambers enables single cells to be subjected to RNA-seq protocols. Another methodology is Fluorescence based flow cytometry (FBFC), which enables to quantify the amount of proteins using fluorophores attached to antibodies. However, because spectral overlap, the maximum number of proteins that can be measured simultaneously is limited. A modification of this technology known as mass cytometry tags antibodies with rare isotopes and uses mass spectrometry to identify proteins. This technique highly improves the dimensionality by increasing the number of proteins and conditions that can be analyzed simultaneously. "],
["bioinformatics-resources.html", "Chapter 4 Bioinformatics resources 4.1 Sequence databases 4.2 Gene expression databases 4.3 Pathway databases 4.4 Domain databases 4.5 Motif databases 4.6 Interaction databases 4.7 Other 4.8 Bioformatics software 4.9 File formats", " Chapter 4 Bioinformatics resources In this chapter some of the most important Bioinformatics resources are described. An attempt to organized them by topic is made, but most of these resources are highly integrated. So, for example, you would thing that to do a Blast search you need to go to the Blast web page. But you can also perform Blast searches from the Uniprot and EnsEMBL web pages, to mention just two. Similarly, most if not all sequence databases link the associated Gene Ontology information to their sequence entries. This high degree of integration might make difficult at first to value the existence of different resources. 4.1 Sequence databases NCBI EnsEMBL EnsEMBL is a database where the genome information about many species is collected with a focus con comparative genomics research. Figure 4.1: Screenshot of the EnsEMBL home page at https://www.ensembl.org. Uniprot The Uniprot website focuses on information about protein sequences, including splice forms. Figure 4.2: Screenshot of the Uniprot home page at http://www.uniprot.org. 4.2 Gene expression databases GEO: Gene Expression Omnibus The Gene Expression Omnibus (GEO) database collects data from high-throughtput experiments including microarrays and NGS datasets. Figure 4.3: Screenshot of the GEO home page at https://www.ncbi.nlm.nih.gov/geo/. The number of submissions per year for microarrays and RNA-seq continues to increase. Figure 4.4: Number of GEO submissions per year for the top 4 technologies. ArrayExpress ArrayExpress is the alternative at the European Bioinformatics Institute. Figure 4.5: Screenshot of the ArrayExpress home page at https://www.ebi.ac.uk/arrayexpress/ 4.3 Pathway databases As information about genes, proteins and metabolites accumulates, it becomes more and more important to organize this knowledge in a comprehensive way. We have mentioned how genes and their products participate in the networks of cellular processes, the cell’s pathway. This network includes metabolic, signaling and gene regulatory networks. This information is critical to understand the cell’s phenotype, but the accumulated knowledge is daunting. It would benefit to have some central repository with easily accessible tools that enables to visualize existing knowledge in an easy way. It would be also very useful if it was possible to use that information in computer analysis. This is the motivation behind some of the web resources described below. KEGG KEGG stands for Kyoto Encyclopedia for Genes and Genomes (Figure 4.6). Is an integrative resource with information about matabolic and signaling pathways in different species, from bacteria and archaea to mammals. Figure 4.6: Screenshot of the KEGG home page at http://www.kegg.jp. Reactome 4.4 Domain databases Pfam Pfam is a database of protein domain families. Proteins are generally comprised of one or more functional regions, commonly termed domains. The presence of different domains in varying combinations in different proteins gives rise to the diverse repertoire of proteins found in nature. Identifying the domains present in a protein can provide insights into the function of that protein. The Pfam database is a large collection of protein domain families. Each family is represented by multiple sequence alignments and a hidden Markov model (HMMs). Figure 4.7: Screenshot of the Pfam home page at http://pfam.xfam.org. 4.5 Motif databases Jaspar Jaspar is a database for transcription factor DNA binding motifs. Figure 4.8: Screenshot of the Jaspar home page at http://jaspar.genereg.net. 4.6 Interaction databases Information about protein-protein interactions has grown incredibly due to advances in MS in combination with affinity purification methods. There are several databases integrating existing information. Two resources will be highlighted here: BioGRID and STRING. BioGRID BioGRID focuses on storing information about PPIs for which experimental evidence exists. Figure 4.9: Screenshot of the BioGRID home page at https://thebiogrid.org. STRING STRING combines experimental and computational evidence to infer PPIs. Figure 4.10: Screenshot of the STRING home page at https://string-db.org. 4.7 Other Gene Ontology One important difficulty when dealing with Biological structures (molecules, organelles, etc.) is the vocabulary we use to described them. As this type of information accumulated different researches would tend to use slighly different ways to describe the same thing. In other cases they can use similar words to describe different things. These nuances make the descriptions often found in publications ambiguous making it difficult to determine the exact meaning of some assertion. This difficulty became more prominent once the amount of information increased dramatically with the advent of omics technologies, and the information about the biological stuff was the subject of computational analyses. There was a need for an standardized nomenclature, and that was the origin of the Gene Ontology project. The purpose of the Gene Ontology project is stated in it web page: The Gene Ontology (GO) project is a major bioinformatics initiative to develop a computational representation of our evolving knowledge of how genes encode biological functions at the molecular, cellular and tissue system levels. Biological systems are so complex that we need to rely on computers to represent this knowledge. The project has developed formal ontologies that represent over 40,000 biological concepts, and are constantly being revised to reflect new discoveries. To date, these concepts have been used to “annotate” gene functions based on experiments reported in over 100,000 peer-reviewed scientific papers. In particular: The Gene Ontology project provides a controlled vocabulary of terms for describing gene product characteristics and gene product annotation data from GO Consortium members, as well as tools to access and process these data. Figure 4.11: Screenshot of the Gene Ontology home page at http://www.geneontology.org. 4.8 Bioformatics software 4.8.1 Sequence analysis Blast The Blast web page at NCBI is the main point of access to this versitile tool. It can be used to search for sequence similarity against any of the sequence databases at the NCBI. Figure 4.12: Screenshot of the Blast home page at https://blast.ncbi.nlm.nih.gov. HMMER HMMER implements Hidden Markov Models for the analysis of biological sequences. It can learn models representing motifs, domains or entire sequences. These models are used to search for sequences matching the models in databases. It can also be used to annotate the domains/motifs present in a sequence using a database of domains. PFAM uses HMMER and manually curated MSA of domains to generate a database of protein families (PFAM). The use of HMM for sequence alignment is described in detail in the excellent book Biological sequence analysis: Probabilistic models of proteins and nucleic acids. Figure 4.13: Screenshot of the Hmmer home page at https://www.ebi.ac.uk/Tools/hmmer. Jalview Jalview is a software for sequence analysis. It can visualize sequences, submit them to multiple sequence aligment servers, visualize the resulting MSA, create basic phylogenetic trees and visualize associated structures. Figure 4.14: Screenshot of the Jalview home page at http://www.jalview.org. MEME The MEME-suite is a collection of tools for the discovery of motifs in proteins, DNA and RNA sequences. If can find de-novo motifs (e.g. MEME) or search for known motifs from a motif database (e.g. MAST, FIMO, etc.) Figure 4.15: Screenshot of the MEME-suite home page at http://meme-suite.org. 4.8.2 Next generation sequencing Bowtie2 Bowtie2 is a command line software to align sequence reads obtained from NGS technologies to a reference genome. It requires sequencing data in Fastq format and produces aligments in SAM format. Figure 4.16: Screenshot of the Bowtie2 home page at (http://bowtie-bio.sourceforge.net/bowtie2/index.shtml. Samtools 4.8.3 General frameworks Bioconductor Bioconductor is a project providing R packages for the anlysis of omics datasets in the R software. R runs on Windows, Macs and Linux computers. Bioconductor provides tools for the analysis and comprehension of high-throughput genomic data. Bioconductor uses the R statistical programming language, and is open source and open development. Figure 4.17: Screenshot of the Bioconductor home page at http://www.bioconductor.org. Cytoscape Cytoscape is a software for the analysis and visualization of networks. It enables to import network information from online databases and integrate it with omics data like for example gene expression profiles. Cytoscape runs on Windows, Macs and Linux computers. Figure 4.18: Screenshot of Cytoscape showing the HIV sample dataset http://www.cytoscape.org. Galaxy The Galaxy project provides a web platform for the analysis of NGS data. In their own words: Galaxy software framework is an open-source application (distributed under the permissive Academic Free License. Its goal is to develop and maintain a system that enables researchers without informatics expertise to perform computational analyses through the web. A user interacts with Galaxy through the web by uploading and analyzing the data. Galaxy interacts with underlying computational infrastructure (servers that run the analyses and disks that store the data) without exposing it to the user. Figure 4.19: Screenshot of the main Galaxy site at http://usegalaxy.org. 4.9 File formats FASTA FASTA is a very simple file format used to store information about biological sequences, including protein, DNA and RNA. Each entry consists of the &gt; character followed by a sequence Id and a description, separated from the Id by a space character. The sequence itself goes in the next lines. Often FASTA files are formatted with a maximum number of residues per line (e.g. 60), which helps when visualizing the information in a regular text editor. &gt;seq1 This is seq1 AGTTAGGATTTGCGCCATT Fastq FASTQ is a format used to store information from NGS technologies. In particular, stores the sequences of the reads in addition to information about the quality of sequencing. Each entry starts with the @ character. That line also contains other information like the read identifier. The next line is the sequence information. Next there is a line with the + character, and then is the quality information encoded as a phred score of the same length as the sequence. @K00211:114:H52N5BBXX:1:2125:22252:26301 TTCCTATATAATCTTTATTTCTGGAAGTTAAAGTAGTTACAGCAATATACAAAAACAAACAACAACAAAAAACAACCCACAATAATATAAATTTTTACAC + AAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJJJJJJJJJJJJJJJJJJJJ SAM "],
["reproducible-research.html", "Chapter 5 Reproducible research 5.1 Git 5.2 Literate programming", " Chapter 5 Reproducible research An important topic in Bioinformatics as a research tools is reproducibility. Bioinformatics pipelines typically require numerous steps in which different parameters can change and affect the results. Also, software sometimes gets updated and not always updates are backbard compatible in the sense that changes in the underlying algorithms results in changes in the results. It is desirable to use a system that encourages transparent reports that enable to repeat the steps used during a particular analysis in order to reproduce the reported results. In this chapter we briefly describe some of the tools used by the modern Bioinformatician to accomplish this. 5.1 Git Github Gitlab 5.2 Literate programming RMarkdown notebooks Jupyter notebooks "],
["learning-bioinformatics.html", "Chapter 6 Learning Bioinformatics 6.1 Books 6.2 Online resources", " Chapter 6 Learning Bioinformatics 6.1 Books 6.1.1 Sequence analysis BLAST: An essential guide to the Basic Local Alignment Search Tool Introductory book to the topic of sequence aligments in general and Blast in particular. Includes Perl code. Figure 6.1: Blast. Ian Korf, … O’Reilly, 2003 Biological sequence analysis: Probabilistic models of proteins and nucleic acids Advance level understanding of the theory of sequence aligment and Hidden Markov Models (HMM). Figure 6.2: Biological sequence analysis: Probabilistic models of proteins and nucleic acids. R. Durbin, S. Eddy, … Cambridge, 1998 Molecular evolution and phylogenetics Introductory level book on the topic of inferring phylogenies from sequence information. Figure 6.3: Molecular evolution and phylogenetics. M. Nei, S. Kumar. Oxford University Press, 2000. 6.1.2 Omics technologies 6.2 Online resources 6.2.1 Learning how to use the command line Sometimes using Bioinformatics tools requires to have some knowledge of how to use the command line, specially in Linux/Unix environments. http://linuxcommand.org has a nice introduction to the Linux command line. Another interesting resource is https://www.codecademy.com, providing an interactive learning experience. It offers also paid courses. 6.2.2 Support Communities Learning Bioinformatics, as with any other complex topic, can be daunting. Often Bioinformatics software come with good and detailed documentation and. It is also possible to frequently find short tutorials that can help newcomers get started. It is important to get a good understanding of the methods being used when the goal is to publish your results. The Bioinformatics community can sometimes help in the learning process by providing solutions to the most frequently encountered problems. Here I will highlight some of the most relevant online communities for the Bioinformatician. Biostars Biostars is an online community deboted to answering questions about “bioinformatics, computational genomics and biological data analysis”. Users can post questions, get answers in the same post. There is a rating system that enables to give credit to good questions and answers. It is possible to include comments for further clarification and discussion. Bioinformatics Stack Exchange Another useful resource for solving general questions related to Bioinformatics can be the Bioinformatics Stack Exchange network. These site follows the same phylosohpy of Biostars (indeed, Biostars originated in the old version of Stack Exchange) but offers, in my opinion, a better user inteface. The site is still in beta but most of the Biostars community can be found also in this new site. Bioconductor support site The Bioconductor support site provides support for questions related to the use of Bioconductor, using a similar interface to Biostars. How to use the support sites It is important to remember that online support sites are usually driven by voluntarees that lend their time and expertise to help others. Because the number of questions put in one of these support sites can be very large, it is very helpful if the questions themeselves are written in a way that simplify the work of those willing to help us with our doubts. For example, it is important to write simple yet meaningful titles that summarize what our problem is. This way the community can easily know if the question is related to a topic about which they have expertise. When describing your issues, be as explicit as possible. And whenever possible, include a minimal reproducible example. This is particularly important if you have problems with programming code but it can also apply to using a web server. For example, if you had some problem using a web server to generate a sequence aligment, include all the steps you performed to obtain the error (if any) you obtained. If possible, when needed, include a minimal example dataset to reproduce the error. In this example, it could be a small file with a few sequences that trigger the error. The particulars will depend of the software and problem you are having. But as a rule of thumb it is always helpful to put yourself in the place of those reading your question, and imagining whether that is enough for them to understand your problem. "]
]
